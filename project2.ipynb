{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0c86f8170f58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'mnist'"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mndata = MNIST('./mnist_data')\n",
    "images, labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "images, labels = shuffle(images, labels, random_state=0)\n",
    "test_images, test_labels = shuffle(test_images, test_labels, random_state=0)\n",
    "\n",
    "images = images[:30000]\n",
    "labels = labels[:30000]\n",
    "test_images = test_images[:1000]\n",
    "test_labels = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 1  Euclidian distance\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(images, labels) \n",
    "predictions = neigh.predict(test_images)\n",
    "\n",
    "\n",
    "# problem 1 confusion matrix\n",
    "correct = sum([a == b for a,b in zip(test_labels, predictions)])\n",
    "print \"1 Nearest neighbor success rate (Euclidian distance) =\",correct/1000.0 * 100,\"%\"\n",
    "confusion_mat = confusion_matrix(test_labels, predictions)\n",
    "print \"\\ncounfustion matrix = \\n\",confusion_mat\n",
    "\n",
    "\n",
    "fig, ax = plot_confusion_matrix(figsize=(5,5), conf_mat=confusion_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 1 Manhattan Distance\n",
    "neigh = KNeighborsClassifier(n_neighbors=1,metric='manhattan')\n",
    "neigh.fit(images, labels) \n",
    "predictions = neigh.predict(test_images)\n",
    "\n",
    "\n",
    "# problem 1 Manhattan confusion matrix\n",
    "correct = sum([a == b for a,b in zip(test_labels, predictions)])\n",
    "print \"1 Nearest neighbor success rate (Manhattan distance) =\",correct/1000.0 * 100,\"%\"\n",
    "conf_mat = confusion_matrix(test_labels, predictions)\n",
    "print \"\\ncounfustion matrix = \\n\",conf_mat\n",
    "\n",
    "fig, ax = plot_confusion_matrix(figsize=(5,5), conf_mat=conf_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 2 SVM using SGD\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='modified_huber',epsilon=0.01,n_iter=10)\n",
    "clf.fit(images, labels)\n",
    "\n",
    "predictions = clf.predict(test_images)\n",
    "\n",
    "# Problem 2 Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "correct = sum([a == b for a,b in zip(test_labels, predictions)])\n",
    "\n",
    "print \"SVM using SGDClassifier success rate =\",correct/1000.0 * 100,\"%\"\n",
    "conf_mat = confusion_matrix(test_labels, predictions)\n",
    "print \"\\ncounfustion matrix = \\n\",conf_mat\n",
    "\n",
    "fig, ax = plot_confusion_matrix(figsize=(5,5), conf_mat=conf_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 2 using LinearSVC\n",
    "\n",
    "from sklearn import svm\n",
    "X = images\n",
    "y = labels\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "predictions = clf.predict(test_images)\n",
    "\n",
    "# Problem 2 Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "correct = sum([a == b for a,b in zip(test_labels, predictions)])\n",
    "\n",
    "print \"SVM using SGDClassifier success rate =\",correct/1000.0 * 100,\"%\"\n",
    "conf_mat = confusion_matrix(test_labels, predictions)\n",
    "print \"\\ncounfustion matrix = \\n\",conf_mat\n",
    "\n",
    "fig, ax = plot_confusion_matrix(figsize=(5,5), conf_mat=conf_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 2 using SVC\n",
    "\n",
    "from sklearn import svm\n",
    "X = images\n",
    "y = labels\n",
    "#clf = svm.SVC(decision_function_shape='ovr',kernel='linear')\n",
    "clf = svm.SVC(C=100,decision_function_shape='ovr',kernel='poly',degree=3)\n",
    "clf.fit(X, y)  \n",
    "\n",
    "predictions = clf.predict(test_images)\n",
    "\n",
    "# Problem 2 Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "correct = sum([a == b for a,b in zip(test_labels, predictions)])\n",
    "\n",
    "print \"SVM using SVC(decision_function_shape='ovr',kernel='poly',degree=3) success rate =\",correct/1000.0 * 100,\"%\"\n",
    "conf_mat = confusion_matrix(test_labels, predictions)\n",
    "print \"\\ncounfustion matrix = \\n\",conf_mat\n",
    "\n",
    "fig, ax = plot_confusion_matrix(figsize=(5,5), conf_mat=conf_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Problem 3 Spatial Pyramid Matching \n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "\n",
    "classes = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "train = []\n",
    "training_labels = []\n",
    "\n",
    "test = []\n",
    "testing_labels = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "for c in classes: \n",
    "    \n",
    "    t = sio.loadmat('images/training_matrix/'+c+'.mat')['pyramid_all3']\n",
    "    train.append(t)\n",
    "    d = sio.loadmat('images/testing_matrix/'+c+'.mat')['pyramid_all3']\n",
    "    test.append(d)\n",
    "    training_labels.append([i]*len(t))\n",
    "    testing_labels.append([i]*len(d))\n",
    "    i = i+1\n",
    "\n",
    "training_labels = np.array(training_labels)\n",
    "training_labels = training_labels.flatten()\n",
    "testing_labels = np.array(testing_labels)\n",
    "testing_labels = np.hstack(testing_labels)\n",
    "\n",
    "\n",
    "\n",
    "training_data = np.array(train[0])\n",
    "testing_data = np.array(test[0])\n",
    "for c in range(1,10): \n",
    "\n",
    "    training_data = np.concatenate((training_data,np.array(train[c])),axis=0)\n",
    "    testing_data = np.concatenate((testing_data,np.array(test[c])),axis=0)\n",
    "  \n",
    "print training_data.shape\n",
    "print training_labels.shape\n",
    "print testing_data.shape\n",
    "print testing_labels.shape\n",
    "\n",
    "print training_labels\n",
    "print testing_labels\n",
    "\n",
    "#training_data = csr_matrix(training_data, dtype=np.float64)\n",
    "#testing_data = csr_matrix(testing_data, dtype=np.float64)\n",
    "training_data, training_labels = shuffle(training_data, training_labels, random_state=0)\n",
    "testing_data, testing_labels = shuffle(testing_data, testing_labels, random_state=0)\n",
    "training_data = 10000*training_data\n",
    "testing_data = 10000*testing_data\n",
    "\n",
    "# problem 2 \n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(n_iter=1000, loss='modified_huber')\n",
    "#clf = svm.SVC(decision_function_shape='ovo',kernel='linear',C=10, gamma='auto',probability=True,verbose=True)\n",
    "#clf = svm.LinearSVC(C=100000000,loss='hinge')\n",
    "#clf = svm.SVC(decision_function_shape='ovr',kernel='poly',degree=5, C=100)\n",
    "clf.fit(training_data[:1000], training_labels[:1000])\n",
    "\n",
    "predictions = clf.predict(testing_data[:200])\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# problem 2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "correct = sum([a == b for a,b in zip(testing_labels, predictions)])\n",
    "print correct\n",
    "print \"success rate =\",correct/10000.0 * 100.0,\"%\"\n",
    "print \"\\ncounfustion matrix = \\n\",confusion_matrix(testing_labels, predictions)\n",
    "\n",
    "'''\n",
    "'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from pykernels.basic import RBF\n",
    "\n",
    "from pykernels.regular import Min,GeneralizedHistogramIntersection\n",
    "\n",
    "X = training_data[:1000]\n",
    "y=training_labels[:1000]\n",
    "\n",
    "predictions = []\n",
    "for clf, name in [(SVC(kernel=Min(), C=1000), 'Min')]:\n",
    "    clf.fit(X, y)\n",
    "    print name\n",
    "    print clf\n",
    "    print 'Predictions:', clf.predict(testing_data[:200])\n",
    "    print 'labels: ',testing_labels[:200]\n",
    "    predictions = clf.predict(testing_data[:200])\n",
    "    print 'Accuracy:', accuracy_score(predictions, testing_labels[:200])\n",
    "    print\n",
    "\n",
    "'''\n",
    "'''\n",
    "from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier,OutputCodeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "predictions = OneVsRestClassifier(LinearSVC(random_state=0,C=10000,dual=False,class_weight='balanced')).fit(training_data[:20000], training_labels[:20000]).predict(testing_data[:500])\n",
    "#predictions =OneVsOneClassifier(LinearSVC(random_state=0)).fit(training_data[:4000], training_labels[:4000]).predict(testing_data[:200])\n",
    "#predictions = OutputCodeClassifier(LinearSVC(random_state=0),code_size=30, random_state=0).fit(training_data[:10000], training_labels[:10000]).predict(testing_data[:200])\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "correct = sum([a == b for a,b in zip(testing_labels[:500], predictions)])\n",
    "print correct\n",
    "print \"success rate =\",correct/500.0 * 100.0,\"%\"\n",
    "print \"\\ncounfustion matrix = \\n\",confusion_matrix(testing_labels[:500], predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "# code from TensorFlow MNIST tutorial https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "# setup tensor flow \n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "# define placeholders and training steps \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "# loss function = cross entropy \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "# evaluate model \n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "# define helper functions for neural network layers \n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "\n",
    "# first convolutional layer \n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second convolutional layer \n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# densely/fully connected layer \n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# dropout layer \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# fully connected final layer \n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step1 = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "train_step2 = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "train_step = [(train_step1,'Adam'),(train_step2, 'Gradient Descent')]\n",
    "print(train_step[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4 Convolutional Neural Network \n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step1 = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#train_step2 = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "train_step2 = tf.train.RMSPropOptimizer(0.01).minimize(cross_entropy)\n",
    "train_step = [(train_step1,'Adam'),(train_step2, 'RMSprop')]\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_loss = defaultdict(list)\n",
    "test_loss = defaultdict(list)\n",
    "for j in range(len(train_step)):\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            train_loss[j].append(cross_entropy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0}))\n",
    "            test_loss[j].append(cross_entropy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "        train_step[j][0].run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    \n",
    "    \n",
    "    t = range(10)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.title('Train and test loss for '+train_step[j][1]+' optimization')\n",
    "    plt.plot(t, train_loss[j], 'r', label='train loss')\n",
    "    plt.plot(t, test_loss[j], 'b', label='test loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "    '''\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.title('Training loss over each epoch ('+train_step[j][1]+' Optimization)')\n",
    "    plt.plot(train_loss[j])\n",
    "    plt.ylabel('training loss')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.title('Test loss over each epoch ('+train_step[j][1]+' Optimization)')\n",
    "    plt.plot(test_loss[j])\n",
    "    plt.ylabel('test loss')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.740666\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.805594\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.432523\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1.274614\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 1.127715\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 1.016233\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.931797\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.904623\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.891258\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.790757\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 2.880171\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 1.491411\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 1.120919\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.921536\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.763747\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.667087\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.573752\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.529821\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.480695\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.456472\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 19.815676\n",
      ">> Epoch 2 finished \tANN training loss 13.012750\n",
      ">> Epoch 3 finished \tANN training loss 9.025525\n",
      ">> Epoch 4 finished \tANN training loss 7.295055\n",
      ">> Epoch 5 finished \tANN training loss 6.229197\n",
      ">> Epoch 6 finished \tANN training loss 5.808220\n",
      ">> Epoch 7 finished \tANN training loss 5.241246\n",
      ">> Epoch 8 finished \tANN training loss 4.761866\n",
      ">> Epoch 9 finished \tANN training loss 4.898449\n",
      ">> Epoch 10 finished \tANN training loss 4.430443\n",
      ">> Epoch 11 finished \tANN training loss 4.188848\n",
      ">> Epoch 12 finished \tANN training loss 4.099041\n",
      ">> Epoch 13 finished \tANN training loss 4.149002\n",
      ">> Epoch 14 finished \tANN training loss 4.126827\n",
      ">> Epoch 15 finished \tANN training loss 4.024709\n",
      ">> Epoch 16 finished \tANN training loss 3.837017\n",
      ">> Epoch 17 finished \tANN training loss 3.789805\n",
      ">> Epoch 18 finished \tANN training loss 3.749225\n",
      ">> Epoch 19 finished \tANN training loss 3.768161\n",
      ">> Epoch 20 finished \tANN training loss 3.448430\n",
      ">> Epoch 21 finished \tANN training loss 3.973341\n",
      ">> Epoch 22 finished \tANN training loss 3.486660\n",
      ">> Epoch 23 finished \tANN training loss 3.562496\n",
      ">> Epoch 24 finished \tANN training loss 3.220933\n",
      ">> Epoch 25 finished \tANN training loss 3.473933\n",
      ">> Epoch 26 finished \tANN training loss 3.096372\n",
      ">> Epoch 27 finished \tANN training loss 3.127187\n",
      ">> Epoch 28 finished \tANN training loss 3.654857\n",
      ">> Epoch 29 finished \tANN training loss 3.176199\n",
      ">> Epoch 30 finished \tANN training loss 3.204959\n",
      ">> Epoch 31 finished \tANN training loss 3.372546\n",
      ">> Epoch 32 finished \tANN training loss 3.147058\n",
      ">> Epoch 33 finished \tANN training loss 3.235672\n",
      ">> Epoch 34 finished \tANN training loss 2.879812\n",
      ">> Epoch 35 finished \tANN training loss 2.878245\n",
      ">> Epoch 36 finished \tANN training loss 3.084891\n",
      ">> Epoch 37 finished \tANN training loss 3.132054\n",
      ">> Epoch 38 finished \tANN training loss 2.776393\n",
      ">> Epoch 39 finished \tANN training loss 3.132948\n",
      ">> Epoch 40 finished \tANN training loss 2.989652\n",
      ">> Epoch 41 finished \tANN training loss 2.867335\n",
      ">> Epoch 42 finished \tANN training loss 2.809363\n",
      ">> Epoch 43 finished \tANN training loss 2.884767\n",
      ">> Epoch 44 finished \tANN training loss 3.035932\n",
      ">> Epoch 45 finished \tANN training loss 2.848164\n",
      ">> Epoch 46 finished \tANN training loss 2.913252\n",
      ">> Epoch 47 finished \tANN training loss 2.813828\n",
      ">> Epoch 48 finished \tANN training loss 2.736477\n",
      ">> Epoch 49 finished \tANN training loss 2.766231\n",
      ">> Epoch 50 finished \tANN training loss 2.839658\n",
      ">> Epoch 51 finished \tANN training loss 2.699174\n",
      ">> Epoch 52 finished \tANN training loss 2.548628\n",
      ">> Epoch 53 finished \tANN training loss 2.651098\n",
      ">> Epoch 54 finished \tANN training loss 2.472910\n",
      ">> Epoch 55 finished \tANN training loss 2.586327\n",
      ">> Epoch 56 finished \tANN training loss 2.511920\n",
      ">> Epoch 57 finished \tANN training loss 2.684920\n",
      ">> Epoch 58 finished \tANN training loss 2.370807\n",
      ">> Epoch 59 finished \tANN training loss 2.716494\n",
      ">> Epoch 60 finished \tANN training loss 2.562766\n",
      ">> Epoch 61 finished \tANN training loss 2.397317\n",
      ">> Epoch 62 finished \tANN training loss 2.461418\n",
      ">> Epoch 63 finished \tANN training loss 2.493879\n",
      ">> Epoch 64 finished \tANN training loss 2.541392\n",
      ">> Epoch 65 finished \tANN training loss 2.619213\n",
      ">> Epoch 66 finished \tANN training loss 2.511461\n",
      ">> Epoch 67 finished \tANN training loss 2.588723\n",
      ">> Epoch 68 finished \tANN training loss 2.558595\n",
      ">> Epoch 69 finished \tANN training loss 2.794101\n",
      ">> Epoch 70 finished \tANN training loss 2.243804\n",
      ">> Epoch 71 finished \tANN training loss 2.400391\n",
      ">> Epoch 72 finished \tANN training loss 2.415319\n",
      ">> Epoch 73 finished \tANN training loss 2.235596\n",
      ">> Epoch 74 finished \tANN training loss 2.320560\n",
      ">> Epoch 75 finished \tANN training loss 2.365965\n",
      ">> Epoch 76 finished \tANN training loss 2.373090\n",
      ">> Epoch 77 finished \tANN training loss 2.344638\n",
      ">> Epoch 78 finished \tANN training loss 2.370614\n",
      ">> Epoch 79 finished \tANN training loss 2.378325\n",
      ">> Epoch 80 finished \tANN training loss 2.296690\n",
      ">> Epoch 81 finished \tANN training loss 2.207147\n",
      ">> Epoch 82 finished \tANN training loss 2.213116\n",
      ">> Epoch 83 finished \tANN training loss 2.479594\n",
      ">> Epoch 84 finished \tANN training loss 2.184803\n",
      ">> Epoch 85 finished \tANN training loss 2.145601\n",
      ">> Epoch 86 finished \tANN training loss 2.331894\n",
      ">> Epoch 87 finished \tANN training loss 2.236025\n",
      ">> Epoch 88 finished \tANN training loss 2.343825\n",
      ">> Epoch 89 finished \tANN training loss 1.923268\n",
      ">> Epoch 90 finished \tANN training loss 2.162285\n",
      ">> Epoch 91 finished \tANN training loss 2.198585\n",
      ">> Epoch 92 finished \tANN training loss 2.443944\n",
      ">> Epoch 93 finished \tANN training loss 2.322807\n",
      ">> Epoch 94 finished \tANN training loss 2.092216\n",
      ">> Epoch 95 finished \tANN training loss 2.326477\n",
      ">> Epoch 96 finished \tANN training loss 2.240110\n",
      ">> Epoch 97 finished \tANN training loss 2.341988\n",
      ">> Epoch 98 finished \tANN training loss 1.917154\n",
      ">> Epoch 99 finished \tANN training loss 2.006803\n",
      ">> Epoch 100 finished \tANN training loss 1.919281\n",
      "[END] Fine tuning step\n",
      "Done.\n",
      "Accuracy: 0.997222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "\n",
    "#from dbn.tensorflow import SupervisedDBNClassification\n",
    "from dbn import SupervisedDBNClassification\n",
    "\n",
    "# Loading dataset\n",
    "digits = load_digits()\n",
    "X, Y = digits.data, digits.target\n",
    "\n",
    "# Data scaling\n",
    "X = (X / 16).astype(np.float32)\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training\n",
    "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
    "                                         learning_rate_rbm=0.05,\n",
    "                                         learning_rate=0.1,\n",
    "                                         n_epochs_rbm=10,\n",
    "                                         n_iter_backprop=100,\n",
    "                                         batch_size=32,\n",
    "                                         activation_function='relu',\n",
    "                                         dropout_p=0.2)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Test\n",
    "Y_pred = classifier.predict(X_test)\n",
    "print('Done.\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ada6097f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = classifier._compute_output_units_matrix(classifier.transform(X_test))\n",
    "'''\n",
    "model = TSNE(n_components=2,  random_state=0, init='pca')\n",
    "np.set_printoptions(suppress=True)\n",
    "Y = model.fit_transform(X) \n",
    "\n",
    "t = np.arange(len(Y))\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=Y[:, 0], cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE\")\n",
    "#ax.xaxis.set_major_formatter(NullFormatter())\n",
    "#ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "mds = manifold.MDS(n_components=10, max_iter=100, n_init=1)\n",
    "Y = mds.fit_transform(X)\n",
    "\n",
    "plt.title(\"MDS\")\n",
    "plt.scatter(Y[:, 0], Y[:, 1],c=Y[:, 0],  cmap=plt.cm.Spectral)\n",
    "\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
